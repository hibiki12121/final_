\chapter{LLMによるグレーゾーンの主観客観判定 \label{c6}}


\section{LLMによるグレーゾーンの主観客観判定 \label{c6s2}}
LLMは説明不可能なAIであるため，話しことば／書きことばの分類が有効であるかの妥当性を判断することは難しい．そこで，先行研究で使用したBERTモデルによるグレーゾーンを含む文章の主観客観の分類タスクをLLMに行わせた．

本検証では，BERTモデル構築の時に使われた山下が作成したグレーゾーン「てしまう」を含む例文を集めたデータセット475件を用いた．これに対し，以下のようなプロンプトを与え，ChatGPTにグレーゾーンの分類を行わせた．

\input{table/ambiguous-sbj-obj}

\subsubsection{検証方法}
プロンプトの構成は，ChatGPTに役割を課す「役割」，取り組んでほしいタスクを示した「指示」，どのようにタスクを取り組むかの例題を記した「例」，出力形式を定めた「フォーマット」，実際に判定してもらう文を記した「判定する文章」の5段で編成した．検証では，「判定する文章」の個数を変えて一度に解かせる量を変化させた場合と，分類時の解答方法を変えた場合で行っている．
また，「例」で使用しているグレーゾーンを含む文章は，データセット構築後新たに追加されたものを使用しており，先行研究\cite{ai-checker}で構築されたBERTモデルの検証データで使われていないものを選択している．

\input{table/prompt-SpokenOrWritten}
検証は，以下の項目で行った．
\begin{enumerate}
    \item 主観または客観に分類されている文章を20件ずつ，LLMに主観または客観に分類させる
    \item 主観または客観に分類されている文章を40件ずつ，LLMに主観または客観に分類させる
    \item 主観または客観に分類されている文章を20件ずつ，LLMに話しことばまたは書きことばに分類させる
    \item 主観または客観に分類されている文章を40件ずつ，LLMに話しことばまたは書きことばに分類させる
\end{enumerate}
話しことばまたは書きことばへの分類は，先行研究\cite{checker}の仮定を採用している．

ChatGPTのブラウザ版を使用し，表\ref{prompt-spokenorwritten}と山下が作成したデータセットを40件ずつに分けて回答を生成させたとき，20件ずつに分けて回答を生成させたときのそれぞれで行った．結果の集計は通常の二値分類と同様に，データセットの分類とChatGPTの分類との一致・不一致をそれぞれ集計している．

以上の検証方法を，Zero-shot Prompting, Few-shot Prompting(n=7, 13) の手法で行い，例の組数を変えたことによるChatGPTの回答結果を比較した.ただし，例の組数は話しことば(主観的)，書きことば(客観的)の1文ずつ1組として数えている．

\subsection{Zero-shot Promptingでの分類の結果 \label{c6s1-1}}

Zero-shot Promptingでの回答結果の評価を表\ref{cfm-ex0}に示す．各々の条件での混合行列は表\ref{cf-ex0-sw20}，表\ref{cf-ex0-sw40}，表\ref{cf-ex0-so20}，表\ref{cf-ex0-so40}に示す．

\input{table/cfm-ex0}
\input{table/cf-ex0-sw20}
\input{table/cf-ex0-sw40}
\input{table/cf-ex0-so20}
\input{table/cf-ex0-so40}

話しことば/書きことば分類(40件ずつ)のときのAccuracyが75.32\%で最も高く，適合率も85.63\%と，こちらも最も高い結果が得られた．また，混同行列からは，どの条件においてもPrecisionの数値が高く，話しことば(主観)であるものを正しく判定できる観点での精度が高いことがわかる．

\subsection{考察}
「てしまう」の分類例を与えずにChatGPTに分類をさせたとき，話しことばまたは書きことばとみなして分類させた方が全体の正解率が高くなった．これは，ChatGPTが持つ話しことば・書きことばの認識が主観・客観の認識よりもしやすいことが考えられる．また，一度に分類させる量が多いときの精度が高いことから，分類時に文脈を考慮しながら判定が行えるようになっていることがが考えられる．

\subsection{Few-shot Promptingでの分類の結果(1) \label{c6s1-2}}
例の件数を7件に増やしたときのFew-shot Promptingでの回答結果の評価を表\ref{cfm-ex7}に示す．各々の条件での混合行列は表\ref{cf-ex7-sw20}，表\ref{cf-ex7-sw40}，表\ref{cf-ex7-so20}，表\ref{cf-ex7-so40}に示す．

\input{table/cfm-ex7}
\input{table/cf-ex7-sw20}
\input{table/cf-ex7-sw40}
\input{table/cf-ex7-so20}
\input{table/cf-ex7-so40}

\subsection{考察}
例の数を増やしたが，\ref{c6s1-1}節の結果と大きな変化がないまたはそれよりも低い結果が得られた．混合行列からは話しことば(主観)であるものを正しく判定した個数が多いことから，話しことばの特性がつかみやすいことが考えられる．

\subsection{Few-shot Promptingでの分類の結果(2) \label{c6s1-3}}
例の組数を13件に増やしたときのFew-shot Promptingでの回答結果の評価を表\ref{cfm-ex13}に示す．各々の条件での混合行列は表\ref{cf-ex13-sw20}，表\ref{cf-ex13-sw40}，表\ref{cf-ex13-so20}，表\ref{cf-ex13-so40}に示す．

\input{table/cfm-ex13}
\input{table/cf-ex13-sw20}
\input{table/cf-ex13-sw40}
\input{table/cf-ex13-so20}
\input{table/cf-ex13-so40}

\subsection{考察}
例の数をさらに増やしたところ，正解率は\ref{c6s1-1}節よりも高い結果が得られた．これは，例を増やしたことにより，文脈をより正確にとらえられるようになったことが考えられる．また，先行研究\cite{ai-checker}で記録した精度と同等であることから，分類タスクでの応用が考えられる．
一方で，20件ずつ解かせている場合の正解率は\ref{c6s1-1}節とほとんど変化は無かった．これは，前述の通り解かせる量が多く，分類時に文脈を考慮しながら判定が行えるからであると考えられる．

% \subsection{追加検証}
% 一度に解かせる文章が多いと精度が高くなるという結果が得られた．このことより，プロンプトに載せる文章の数によって，精度の向上が期待できる．そこで，話しことば／書きことばへの分類タスクで一度に解かせる量を20件にしているものについて，例の数を追加し，文章の総数を40件の場合と同じ個数，すなわち例33組，分類させる文章20件，計86文をプロンプトに組み込んで分類させた．